{
 "cells": [
  {
   "cell_type": "raw",
   "id": "6ecace31-91d8-4185-aa84-141a1181db63",
   "metadata": {},
   "source": [
    "Implement the Continuous Bag of Words (CBOW) Model for the given (textual document \n",
    "3) using the below steps: \n",
    "a. Data preparation \n",
    "b. Generate training data \n",
    "c. Train model \n",
    "d. Output "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cfdc0456-dc50-4fa9-961e-17b5ee220906",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Dense, Flatten\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2838d876-5399-4675-bb00-0fa0e747cb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# REPLACE THIS WITH YOUR TEXTUAL DOCUMENT 3\n",
    "text = \"\"\"\n",
    "    Artificial intelligence and machine learning are transforming industries. \n",
    "    Companies use data to train models that can understand language, \n",
    "    make predictions, and automate complex tasks.\n",
    "\"\"\"\n",
    "# PUT YOUR DOCUMENT 3 ABOVE ↑↑↑"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a0ea5bb3-7447-4a3e-be9f-f3dbb332f78d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 24\n",
      "Sequence: [2, 3, 1, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 1, 21, 22, 23]\n"
     ]
    }
   ],
   "source": [
    "# Tokenization\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts([text])\n",
    "\n",
    "word_index = tokenizer.word_index\n",
    "index_word = {v: k for k, v in word_index.items()}\n",
    "vocab_size = len(word_index) + 1\n",
    "\n",
    "sequence = tokenizer.texts_to_sequences([text])[0]\n",
    "\n",
    "print(\"Vocabulary Size:\", vocab_size)\n",
    "print(\"Sequence:\", sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d43e69b-a36e-4d26-aca2-66d2ce575244",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Context samples:\n",
      " [[2 3 4 5]\n",
      " [3 1 5 6]\n",
      " [1 4 6 7]\n",
      " [4 5 7 8]\n",
      " [5 6 8 9]]\n",
      "\n",
      "Target samples:\n",
      " [1 4 5 6 7]\n"
     ]
    }
   ],
   "source": [
    "# b. Generate Training Data (CBOW)\n",
    "\n",
    "window_size = 2\n",
    "X_train = []\n",
    "y_train = []\n",
    "\n",
    "for i in range(window_size, len(sequence) - window_size):\n",
    "    context = [\n",
    "        sequence[i - 2],\n",
    "        sequence[i - 1],\n",
    "        sequence[i + 1],\n",
    "        sequence[i + 2]\n",
    "    ]\n",
    "    target = sequence[i]\n",
    "\n",
    "    X_train.append(context)\n",
    "    y_train.append(target)\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "y_train = np.array(y_train)\n",
    "\n",
    "print(\"\\nContext samples:\\n\", X_train[:5])\n",
    "print(\"\\nTarget samples:\\n\", y_train[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "732d5eb2-ae65-47db-b95a-f8823a62878f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)                   │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ embedding (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Embedding</span>)                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                │             <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>)                │              <span style=\"color: #00af00; text-decoration-color: #00af00\">72</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)                  │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">24</span>)                  │             <span style=\"color: #00af00; text-decoration-color: #00af00\">792</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ input_layer (\u001b[38;5;33mInputLayer\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)                   │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ embedding (\u001b[38;5;33mEmbedding\u001b[0m)                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m8\u001b[0m)                │             \u001b[38;5;34m192\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m8\u001b[0m)                │              \u001b[38;5;34m72\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)                  │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m24\u001b[0m)                  │             \u001b[38;5;34m792\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> (4.12 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m1,056\u001b[0m (4.12 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,056</span> (4.12 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m1,056\u001b[0m (4.12 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CBOW Model Training Complete!\n"
     ]
    }
   ],
   "source": [
    "# c. Train Model (CBOW)\n",
    "\n",
    "embedding_dim = 8\n",
    "\n",
    "input_layer = Input(shape=(4,))\n",
    "embedding_layer = Embedding(vocab_size, embedding_dim)(input_layer)\n",
    "\n",
    "hidden = Dense(embedding_dim, activation=\"linear\")(embedding_layer)\n",
    "hidden = Flatten()(hidden)\n",
    "\n",
    "output_layer = Dense(vocab_size, activation=\"softmax\")(hidden)\n",
    "\n",
    "cbow_model = Model(inputs=input_layer, outputs=output_layer)\n",
    "cbow_model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\")\n",
    "\n",
    "cbow_model.summary()\n",
    "\n",
    "cbow_model.fit(X_train, y_train, epochs=200, verbose=0)\n",
    "\n",
    "print(\"\\nCBOW Model Training Complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60c2eb6e-a75f-4b23-9159-21e2bd784f9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Word Embeddings:\n",
      "and → [ 0.33388063  0.23897627 -0.00245166 -0.34911847  0.19323072 -0.1758215\n",
      " -0.30447924  0.3047515 ]\n",
      "artificial → [ 0.10225158 -0.18491912 -0.22186331  0.09288968 -0.16419594 -0.22215068\n",
      "  0.18461749 -0.26058343]\n",
      "intelligence → [-0.3011102   0.27340502  0.29981354  0.20266679 -0.30358985  0.13303886\n",
      " -0.28277218  0.11462356]\n",
      "machine → [-0.17299399  0.3010616   0.32244766  0.2808829  -0.25201517  0.2042182\n",
      " -0.04099383 -0.19004552]\n",
      "learning → [ 0.32577705 -0.10726667 -0.16211052 -0.4324983   0.32738975  0.01339934\n",
      "  0.26947537  0.22899538]\n",
      "are → [ 0.40127534  0.35410333  0.33594838 -0.23192279  0.29714763  0.37725812\n",
      " -0.1955886   0.45401743]\n",
      "transforming → [-0.26276848  0.42021564  0.3244319   0.3972211  -0.396914    0.10345405\n",
      "  0.29359192 -0.3238096 ]\n",
      "industries → [-0.29452285 -0.01761549 -0.05606993  0.10231233 -0.2870479  -0.18836977\n",
      "  0.26843014 -0.27133512]\n",
      "companies → [-0.37942615 -0.08160608 -0.12732147  0.11819732 -0.19914638 -0.25165638\n",
      "  0.25201163 -0.34859833]\n",
      "use → [0.281964   0.22529928 0.26101437 0.08104368 0.04901779 0.16801786\n",
      " 0.08177698 0.28151706]\n",
      "data → [-0.44050515 -0.26156327 -0.30653363 -0.06173829 -0.10248089 -0.31014758\n",
      "  0.06260408 -0.279012  ]\n",
      "to → [ 0.03626994 -0.46799982 -0.3946446  -0.24228553  0.31898507 -0.08243214\n",
      " -0.30395266  0.18304312]\n",
      "train → [-0.29705554  0.3440061   0.28749856  0.03231809 -0.26540944  0.3404792\n",
      "  0.3890699   0.21716581]\n",
      "models → [ 0.19045892 -0.21075985 -0.19864745 -0.3125806   0.30461854  0.09641878\n",
      " -0.07295749  0.36745256]\n",
      "that → [ 0.00471725 -0.34443074 -0.3585258  -0.2386519   0.3197568  -0.15282969\n",
      " -0.35931084  0.29822326]\n",
      "can → [-0.3088405  -0.01521224  0.2190248   0.35284296  0.18313998  0.42690665\n",
      " -0.43269378  0.3657373 ]\n",
      "understand → [ 0.1815231  -0.23673248 -0.1150431  -0.38186082  0.3498542  -0.11776046\n",
      " -0.35104534  0.4359237 ]\n",
      "language → [ 0.11990479  0.4648002   0.4280144   0.32380018 -0.04316461  0.3108089\n",
      " -0.1422785   0.04299333]\n",
      "make → [-0.13857473 -0.24901038 -0.30173734  0.18351264 -0.32784894 -0.40459132\n",
      "  0.38424438 -0.39186436]\n",
      "predictions → [-0.14709991  0.46887687  0.35926077  0.17542517 -0.2268062   0.25664923\n",
      " -0.3739738   0.05000281]\n",
      "automate → [-0.0110132   0.16207273  0.19126117  0.28775972 -0.14890736 -0.21161756\n",
      " -0.10118993 -0.13422714]\n",
      "complex → [ 0.29492003 -0.22097167 -0.3086645  -0.25048202  0.28152978 -0.04739049\n",
      " -0.23212686  0.2466259 ]\n",
      "tasks → [-0.0427701  -0.24281314 -0.22405556 -0.22620781 -0.21310529 -0.20881148\n",
      " -0.00135934 -0.21555409]\n"
     ]
    }
   ],
   "source": [
    "# d. Output – Word Embeddings\n",
    "\n",
    "from tensorflow.keras.layers import Embedding\n",
    "\n",
    "embedding_layer_obj = [layer for layer in cbow_model.layers if isinstance(layer, Embedding)][0]\n",
    "weights = embedding_layer_obj.get_weights()[0]\n",
    "\n",
    "print(\"\\nWord Embeddings:\")\n",
    "for word, idx in word_index.items():\n",
    "    print(f\"{word} → {weights[idx]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f1a04af-f9b5-4edb-9f38-ec35bdf8cd54",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Checking Word Similarity:\n",
      "Similarity(learning, intelligence): -0.7753357\n",
      "Similarity(models, predictions): -0.45635945\n",
      "Similarity(data, companies): 0.85118765\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\n",
      "Context: ['machine', 'learning', 'are', 'transforming']\n",
      "Predicted Missing Word: can\n"
     ]
    }
   ],
   "source": [
    "# EXTRA SECTION: CHECK IF CBOW MODEL IS WORKING\n",
    "# =====================================================\n",
    "\n",
    "from numpy import dot\n",
    "from numpy.linalg import norm\n",
    "\n",
    "# Similarity function\n",
    "def similarity(w1, w2):\n",
    "    v1 = weights[word_index[w1]]\n",
    "    v2 = weights[word_index[w2]]\n",
    "    return dot(v1, v2) / (norm(v1) * norm(v2))\n",
    "\n",
    "print(\"\\nChecking Word Similarity:\")\n",
    "print(\"Similarity(learning, intelligence):\", similarity(\"learning\", \"intelligence\"))\n",
    "print(\"Similarity(models, predictions):\", similarity(\"models\", \"predictions\"))\n",
    "print(\"Similarity(data, companies):\", similarity(\"data\", \"companies\"))\n",
    "\n",
    "\n",
    "# Predict the missing target word from context\n",
    "context_words = [\"machine\", \"learning\", \"are\", \"transforming\"]\n",
    "\n",
    "context_ids = np.array([[word_index[w] for w in context_words]])\n",
    "\n",
    "pred = cbow_model.predict(context_ids)\n",
    "predicted_word = index_word[np.argmax(pred)]\n",
    "\n",
    "print(\"\\nContext:\", context_words)\n",
    "print(\"Predicted Missing Word:\", predicted_word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc93566d-4880-4c33-a73d-f162e074d526",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
