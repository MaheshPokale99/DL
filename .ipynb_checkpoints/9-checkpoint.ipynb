{
 "cells": [
  {
   "cell_type": "raw",
   "id": "4ebb8bfa-be17-4750-8218-68feb831b70b",
   "metadata": {},
   "source": [
    " \n",
    "Object detection using Transfer Learning of CNN architectures for the given (image dataset \n",
    "1) using the below steps: \n",
    "a. Load in a pre-trained CNN model trained on a large dataset \n",
    "b. Freeze parameters (weights) in model's lower convolutional layers \n",
    "c. Add custom classifier with several layers of trainable parameters to model \n",
    "d. Train classifier layers on training data available for task \n",
    "e. Fine-tune hyper parameters and unfreeze more layers as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5456f7d7-6a70-4c60-9d1e-24c520314859",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Flatten, Dropout\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4193e391-1bbb-4de7-a1c8-0b7501e7320e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load your dataset\n",
    "data_dir = r\"dataset\\Object Detection(Ass6)\\caltech-101-img\"\n",
    "\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "batch_size = 32\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1.0/255,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "train_gen = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset=\"training\"\n",
    ")\n",
    "\n",
    "val_gen = datagen.flow_from_directory(\n",
    "    data_dir,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    subset=\"validation\"\n",
    ")\n",
    "\n",
    "num_classes = train_gen.num_classes\n",
    "print(\"Number of classes:\", num_classes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92af2dd8-5469-4439-911d-83a312b6317b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# b. Load Pretrained VGG16 (LOCAL WEIGHTS)\n",
    "\n",
    "vgg = VGG16(\n",
    "    weights=None,\n",
    "    include_top=False,\n",
    "    input_shape=(224, 224, 3)\n",
    ")\n",
    "\n",
    "# Load your local VGG16 weights\n",
    "vgg.load_weights(\n",
    "    r\"dataset\\Object Detection(Ass6)\\vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
    ")\n",
    "\n",
    "print(\"Loaded local VGG16 weights successfully!\")\n",
    "\n",
    "# Freeze all convolution layers\n",
    "for layer in vgg.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3082a573-7f1c-448d-957b-2b29bb5ccfd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# c. Add Custom Classifier\n",
    "\n",
    "x = Flatten()(vgg.output)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "output = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=vgg.input, outputs=output)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.0005),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "341de002-aa1b-495e-bc90-65d7d28bf34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d. Train Classifier Layers\n",
    "\n",
    "history_1 = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d13c37b-1cfd-4c4b-acfb-6418c74447f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# e. Fine-Tune Last Few Layers\n",
    "\n",
    "for layer in vgg.layers[-4:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.0001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history_2 = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9b08c7-fd38-477e-aa1b-0b4b53b5ed1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# f. Evaluate Model\n",
    "\n",
    "loss, acc = model.evaluate(val_gen)\n",
    "print(f\"\\n Validation Accuracy: {acc * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c152819-3200-4bae-87f2-cdc161d72484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# g. Plot Accuracy & Loss Curves\n",
    "\n",
    "def plot_history(h1, h2):\n",
    "    acc = h1.history['accuracy'] + h2.history['accuracy']\n",
    "    val_acc = h1.history['val_accuracy'] + h2.history['val_accuracy']\n",
    "    loss = h1.history['loss'] + h2.history['loss']\n",
    "    val_loss = h1.history['val_loss'] + h2.history['val_loss']\n",
    "\n",
    "    epochs = range(1, len(acc)+1)\n",
    "\n",
    "    plt.figure(figsize=(14,5))\n",
    "\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(epochs, acc, label=\"Train Accuracy\")\n",
    "    plt.plot(epochs, val_acc, label=\"Val Accuracy\")\n",
    "    plt.title(\"Accuracy\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(epochs, loss, label=\"Train Loss\")\n",
    "    plt.plot(epochs, val_loss, label=\"Val Loss\")\n",
    "    plt.title(\"Loss\")\n",
    "    plt.legend()\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "plot_history(history_1, history_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea050b6-d523-4d2d-a7b1-1a788e671457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# h. Predict on Single Image\n",
    "\n",
    "import tensorflow.keras.preprocessing.image as kp\n",
    "\n",
    "test_path = r\"dataset\\Object Detection(Ass6)\\caltech-101-img\\accordion\\image_0001.jpg\"\n",
    "\n",
    "img = kp.load_img(test_path, target_size=(224,224))\n",
    "img_arr = kp.img_to_array(img) / 255.0\n",
    "img_arr = np.expand_dims(img_arr, axis=0)\n",
    "\n",
    "pred = model.predict(img_arr)\n",
    "class_id = np.argmax(pred)\n",
    "class_name = list(train_gen.class_indices.keys())[class_id]\n",
    "\n",
    "print(\"\\nPredicted Class:\", class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99555eea-6931-49fc-93b4-51a66f3103cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
