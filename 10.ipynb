{
 "cells": [
  {
   "cell_type": "raw",
   "id": "d5c11bef-3b06-4746-9b19-e543f8c744fd",
   "metadata": {},
   "source": [
    "Object detection using Transfer Learning of CNN architectures for the given (image dataset \n",
    "2) using the below steps: \n",
    "a. Load in a pre-trained CNN model trained on a large dataset \n",
    "b. Freeze parameters (weights) in model's lower convolutional layers \n",
    "c. Add custom classifier with several layers of trainable parameters to model \n",
    "d. Train classifier layers on training data available for task \n",
    "e. Fine-tune hyper parameters and unfreeze more layers as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71054b1b-85a8-4e72-949c-08976a6c09ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications import VGG16\n",
    "from tensorflow.keras.layers import Flatten, Dense, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aa91b047-1036-49ff-ab59-9b7f02c3f131",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'D:dataset\\\\Object Detection(Ass6)\\\\dataset2'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 14\u001b[39m\n\u001b[32m      7\u001b[39m batch_size = \u001b[32m32\u001b[39m\n\u001b[32m      9\u001b[39m datagen = ImageDataGenerator(\n\u001b[32m     10\u001b[39m     rescale=\u001b[32m1.\u001b[39m/\u001b[32m255\u001b[39m,\n\u001b[32m     11\u001b[39m     validation_split=\u001b[32m0.2\u001b[39m\n\u001b[32m     12\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m train_gen = \u001b[43mdatagen\u001b[49m\u001b[43m.\u001b[49m\u001b[43mflow_from_directory\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdataset2_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg_height\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimg_width\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m    \u001b[49m\u001b[43mclass_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mcategorical\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m    \u001b[49m\u001b[43msubset\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtraining\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n\u001b[32m     20\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     22\u001b[39m val_gen = datagen.flow_from_directory(\n\u001b[32m     23\u001b[39m     dataset2_path,\n\u001b[32m     24\u001b[39m     target_size=(img_height, img_width),\n\u001b[32m   (...)\u001b[39m\u001b[32m     27\u001b[39m     subset=\u001b[33m\"\u001b[39m\u001b[33mvalidation\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     28\u001b[39m )\n\u001b[32m     30\u001b[39m num_classes = train_gen.num_classes\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py:1136\u001b[39m, in \u001b[36mImageDataGenerator.flow_from_directory\u001b[39m\u001b[34m(self, directory, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio)\u001b[39m\n\u001b[32m   1118\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mflow_from_directory\u001b[39m(\n\u001b[32m   1119\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   1120\u001b[39m     directory,\n\u001b[32m   (...)\u001b[39m\u001b[32m   1134\u001b[39m     keep_aspect_ratio=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m   1135\u001b[39m ):\n\u001b[32m-> \u001b[39m\u001b[32m1136\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDirectoryIterator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1137\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1138\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m   1139\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1140\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcolor_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcolor_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1141\u001b[39m \u001b[43m        \u001b[49m\u001b[43mkeep_aspect_ratio\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_aspect_ratio\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1142\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclasses\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclasses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1143\u001b[39m \u001b[43m        \u001b[49m\u001b[43mclass_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mclass_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1144\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdata_format\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdata_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1145\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1146\u001b[39m \u001b[43m        \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m=\u001b[49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1147\u001b[39m \u001b[43m        \u001b[49m\u001b[43mseed\u001b[49m\u001b[43m=\u001b[49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1148\u001b[39m \u001b[43m        \u001b[49m\u001b[43msave_to_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43msave_to_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1149\u001b[39m \u001b[43m        \u001b[49m\u001b[43msave_prefix\u001b[49m\u001b[43m=\u001b[49m\u001b[43msave_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1150\u001b[39m \u001b[43m        \u001b[49m\u001b[43msave_format\u001b[49m\u001b[43m=\u001b[49m\u001b[43msave_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1151\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_links\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_links\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1152\u001b[39m \u001b[43m        \u001b[49m\u001b[43msubset\u001b[49m\u001b[43m=\u001b[49m\u001b[43msubset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1153\u001b[39m \u001b[43m        \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[43m=\u001b[49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1154\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1155\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\keras\\src\\legacy\\preprocessing\\image.py:456\u001b[39m, in \u001b[36mDirectoryIterator.__init__\u001b[39m\u001b[34m(self, directory, image_data_generator, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, follow_links, subset, interpolation, keep_aspect_ratio, dtype)\u001b[39m\n\u001b[32m    454\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m classes:\n\u001b[32m    455\u001b[39m     classes = []\n\u001b[32m--> \u001b[39m\u001b[32m456\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m subdir \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(\u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m)\u001b[49m):\n\u001b[32m    457\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m os.path.isdir(os.path.join(directory, subdir)):\n\u001b[32m    458\u001b[39m             classes.append(subdir)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [WinError 3] The system cannot find the path specified: 'D:dataset\\\\Object Detection(Ass6)\\\\dataset2'"
     ]
    }
   ],
   "source": [
    "# a. LOAD PREPARED DATASET 2\n",
    "\n",
    "dataset2_path = r\"D:dataset/Object Detection(Ass6)\"\n",
    "\n",
    "img_height = 224\n",
    "img_width = 224\n",
    "batch_size = 32\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1./255,\n",
    "    validation_split=0.2\n",
    ")\n",
    "\n",
    "train_gen = datagen.flow_from_directory(\n",
    "    dataset2_path,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\",\n",
    "    subset=\"training\"\n",
    ")\n",
    "\n",
    "val_gen = datagen.flow_from_directory(\n",
    "    dataset2_path,\n",
    "    target_size=(img_height, img_width),\n",
    "    batch_size=batch_size,\n",
    "    class_mode=\"categorical\",\n",
    "    subset=\"validation\"\n",
    ")\n",
    "\n",
    "num_classes = train_gen.num_classes\n",
    "print(\"\\nNumber of Classes Found:\", num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "34276e4b-cda9-488a-9281-3c55097cd91c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded VGG16 Pretrained Weights Successfully!\n"
     ]
    }
   ],
   "source": [
    "# b. LOAD PRE-TRAINED CNN (VGG16)\n",
    "vgg = VGG16(\n",
    "    weights=None,                \n",
    "    include_top=False,\n",
    "    input_shape=(224, 224, 3)\n",
    ")\n",
    "\n",
    "vgg.load_weights(\n",
    "    r\"dataset\\Object Detection(Ass6)\\vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\"\n",
    ")\n",
    "\n",
    "print(\"\\nLoaded VGG16 Pretrained Weights Successfully!\")\n",
    "\n",
    "\n",
    "# Freeze all convolutional layers\n",
    "for layer in vgg.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d7b08811-e8a3-41a1-9e9c-426993986aae",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'num_classes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      6\u001b[39m x = Dense(\u001b[32m256\u001b[39m, activation=\u001b[33m'\u001b[39m\u001b[33mrelu\u001b[39m\u001b[33m'\u001b[39m)(x)\n\u001b[32m      7\u001b[39m x = Dropout(\u001b[32m0.3\u001b[39m)(x)\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m output = Dense(\u001b[43mnum_classes\u001b[49m, activation=\u001b[33m'\u001b[39m\u001b[33msoftmax\u001b[39m\u001b[33m'\u001b[39m)(x)\n\u001b[32m     10\u001b[39m model = Model(inputs=vgg.input, outputs=output)\n\u001b[32m     12\u001b[39m model.compile(\n\u001b[32m     13\u001b[39m     optimizer=Adam(learning_rate=\u001b[32m0.0005\u001b[39m),\n\u001b[32m     14\u001b[39m     loss=\u001b[33m'\u001b[39m\u001b[33mcategorical_crossentropy\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     15\u001b[39m     metrics=[\u001b[33m'\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     16\u001b[39m )\n",
      "\u001b[31mNameError\u001b[39m: name 'num_classes' is not defined"
     ]
    }
   ],
   "source": [
    "# c. ADD CUSTOM CLASSIFIER\n",
    "\n",
    "x = Flatten()(vgg.output)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(256, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "output = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=vgg.input, outputs=output)\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.0005),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "291ba0fc-581a-4ab4-ad19-7debb354d889",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[7]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# d. Train classifier layers (with backbone frozen)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m history_1 = \u001b[43mmodel\u001b[49m.fit(\n\u001b[32m      4\u001b[39m     train_gen,\n\u001b[32m      5\u001b[39m     validation_data=val_gen,\n\u001b[32m      6\u001b[39m     epochs=\u001b[32m10\u001b[39m\n\u001b[32m      7\u001b[39m )\n",
      "\u001b[31mNameError\u001b[39m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# d. Train classifier layers (with backbone frozen)\n",
    "\n",
    "history_1 = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a54757ce-44bc-4267-b92b-3ff572fef3da",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 7\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m layer \u001b[38;5;129;01min\u001b[39;00m vgg.layers[-\u001b[32m4\u001b[39m:]:\n\u001b[32m      5\u001b[39m     layer.trainable = \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m7\u001b[39m \u001b[43mmodel\u001b[49m.compile(\n\u001b[32m      8\u001b[39m     optimizer=Adam(learning_rate=\u001b[32m0.0001\u001b[39m),\n\u001b[32m      9\u001b[39m     loss=\u001b[33m'\u001b[39m\u001b[33mcategorical_crossentropy\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     10\u001b[39m     metrics=[\u001b[33m'\u001b[39m\u001b[33maccuracy\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     11\u001b[39m )\n\u001b[32m     13\u001b[39m history_2 = model.fit(\n\u001b[32m     14\u001b[39m     train_gen,\n\u001b[32m     15\u001b[39m     validation_data=val_gen,\n\u001b[32m     16\u001b[39m     epochs=\u001b[32m5\u001b[39m\n\u001b[32m     17\u001b[39m )\n",
      "\u001b[31mNameError\u001b[39m: name 'model' is not defined"
     ]
    }
   ],
   "source": [
    "# e. Fine-tune hyperparameters and unfreeze more layers\n",
    "\n",
    "# Unfreeze last 4 layers of VGG16\n",
    "for layer in vgg.layers[-4:]:\n",
    "    layer.trainable = True\n",
    "\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.0001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history_2 = model.fit(\n",
    "    train_gen,\n",
    "    validation_data=val_gen,\n",
    "    epochs=5\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9d7872-c0ce-41eb-b32d-0b6b0f2043ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FINAL MODEL EVALUATION\n",
    "\n",
    "loss, accuracy = model.evaluate(val_gen)\n",
    "print(f\"\\nâœ… Final Validation Accuracy: {accuracy*100:.2f}%\")\n",
    "\n",
    "\n",
    "# ---------------------------------------------------------\n",
    "# TRAINING PLOTS\n",
    "# ---------------------------------------------------------\n",
    "\n",
    "def plot_results(h1, h2):\n",
    "    acc = h1.history['accuracy'] + h2.history['accuracy']\n",
    "    val_acc = h1.history['val_accuracy'] + h2.history['val_accuracy']\n",
    "    loss = h1.history['loss'] + h2.history['loss']\n",
    "    val_loss = h1.history['val_loss'] + h2.history['val_loss']\n",
    "\n",
    "    epochs = range(1, len(acc)+1)\n",
    "\n",
    "    plt.figure(figsize=(14,5))\n",
    "\n",
    "    plt.subplot(1,2,1)\n",
    "    plt.plot(epochs, acc, label=\"Train Accuracy\")\n",
    "    plt.plot(epochs, val_acc, label=\"Val Accuracy\")\n",
    "    plt.title(\"Accuracy\")\n",
    "\n",
    "    plt.subplot(1,2,2)\n",
    "    plt.plot(epochs, loss, label=\"Train Loss\")\n",
    "    plt.plot(epochs, val_loss, label=\"Val Loss\")\n",
    "    plt.title(\"Loss\")\n",
    "    plt.show()\n",
    "\n",
    "plot_results(history_1, history_2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
